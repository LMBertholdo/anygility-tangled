#!/usr/bin/env python
# coding: utf-8
###############################################################################
# make-playbook - Create a playbook based on vp-cli statistics and routing 
#               information using command line arguments
#
# Copyright (C) 2022 by University of Twente
# Written by Leandro Bertholdo <leandro.bertholdo@gmail.com>
#
# This program is free software; you can redistribute it and/or
# modify it under the terms of the GNU General Public License,
# version 2, as published by the Free Software Foundation.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License along
# with this program; if not, write to the Free Software Foundation, Inc.,
# 59 Temple Place, Suite 330, Boston, MA 02111-1307, USA.
###############################################################################

import pandas as pd
import glob as glob
import re
import numpy as np
import argparse
import sys
import signal
import logging
import importlib
from IPython.display import display

###############################################################################
### Program settings
program_name = sys.argv[0][:-3]
version = "0.7"

# convert sites to IATA
iata = {
		"au-syd-anycast01": "SYD",
		"br-gru-anycast01": "GRU",
		"br-poa-anycast02": "POA",
		"fr-par-anycast01": "CDG",
		"uk-lnd-anycast02": "LHR",
		"us-sea-anycast01": "SEA",
		"us-los-anycast01": "LAX",
		"us-mia-anycast01": "MIA",
		"us-was-anycast01": "IAD",
		"de-fra-anycast01": "FRA",
		"sg-sin-anycast01": "SIN",
		"dk-cop-anycast01": "COP",
		"za-jnb-anycast01": "JNB",
		"nl-ens-anycast02": "ENS",
		"nl-ams-anycast01": "AMS",
		"nl-arn-anycast01": "ARN", 
} 

#------------------------------------------------------------------------------
def get_bgp_policy(fstats):
    '''
    Extract BGP Routing policy from *.stas files 
    '''
    logging.info(f"Parsing [{fstats}]")
    f = open(fstats, 'r')
    Lines = f.readlines() 
    for line in Lines:
        if re.match("#policy", line):
            #print(f"Line {line}")
            policy=line.split(',')[1]
            return (policy.strip())
    return None

#------------------------------------------------------------------------------
def signal_handler(sig, frame):
    print('Ctrl+C detected.')
    cursor.show()
    sys.exit(0)

#------------------------------------------------------------------------------
def parser_args ():
    parser = argparse.ArgumentParser(prog=program_name, usage='%(prog)s [options]')
    parser.add_argument("--version", help="print version and exit", action="store_true")
    parser.add_argument("-v", help="print verbose messages", action="store_true",dest="verbose")
    parser.add_argument("-d","--debug", help="print debug messages", action="store_true")
    parser.add_argument('--routing', help="add routing information to playbook file", action='store_true')
    parser.add_argument('--dir', help="directory with vp-cli stats files", action='append')
    parser.add_argument('--out', nargs='?', help="File name to save Playbook results")
    parser.add_argument('--fsdb', nargs='?', help="File name to save Playbook in FSDB format (to be used for playbook_tuner)")
    return parser

#------------------------------------------------------------------------------
def check_stats_file(fstats):
    ''' Check stats file if is consistent
        return: True is ok 
                False if is error
    '''
    # Check stats file for more than ohe header
    num_headers=0
    df=pd.read_csv(fstats,comment='#')
    try:
        num_headers=df['site'].value_counts()['site'] # found column name as column data
    except KeyError: 
        # not found 'site' as data... so its good
        return True
    
    # more than one header = two measurements in same file (measurement script with error)
    if num_headers:
        print (f'ERROR:: on file {fstats}')
        print (f'ERROR:: We found ({num_headers}) duplicated header on this file')
        print (f'ERROR:: Check your measurement! More than one measurement is overlapping to same filename!')
        return False
    
    return False

#------------------------------------------------------------------------------
def read_vpcli_stats_folder (stats_dir, routing_option): 
    """ Read all vp-cli *.stats files in folder and return a dataframe
        receive: stats_dir: folder containing *.stats files generated by VP-CLI.py
                 routing_option: False just includes statistics files
                                 True adds statistics and routing information to playbook
        returns: df in format ['site', 'counts', 'percent', 'bgp']
    """ 
    print (f"Building Playbook from {stats_dir}")
    
    # Empty df
    df_all=pd.DataFrame(columns=['site','bgp'])
    
    flist=glob.glob(stats_dir+'/*.stats')
    if not flist:
       print(f'ERROR:: Folder {stats_dir} does not contain *.stats files')
       sys.exit(0)

    # Read stats files from directory
    for fstats in flist:
        logging.info(f"Statistics [{fstats}]")

        # Check if statistics file is OK
        if not check_stats_file(fstats):
            print (f'This file is damaged --> {fstats}')
            print ('Skipping...\n')
            continue 

        # Read stats df
        df=pd.read_csv(fstats,comment='#')
    
        # Add BGP_Policy from stats comments
        df['bgp']=get_bgp_policy(fstats)
            
        # Add Routing information to dataframe
        if (routing_option):
            #routing_info=fstats.split('/')[-1].replace(".stats",".routing",1)            
            routing_info=fstats.replace(".stats",".routing",1)            
            df['routing_info']=routing_info    
            logging.info(f"Added Routing Information [{routing_info}]")
        
        #Check duplicated policies
        if not df_all.empty:
            pol_lst=df_all['bgp'].to_list()
            policy=df['bgp'][0]
            if policy in pol_lst :
                logging.info(f"read_vpcli:: FOUND DUPLICATED POLICY AT {fstats}")
                print(f'WARNING::: This policy [{policy}] already exists!')
                print(f'Check if its ok for you! [{fstats}]')
                print ('Skipping...\n')
                continue    
                
        # Append DF to playbook
        logging.debug(f"read_vpcli:: append df_all {fstats}")
        df_all=df_all.append(df)
        
    # We just want Integers on values
    df_all=df_all.astype({"counts":'int', "percent":'int'})

    # Map site to IATA code
    logging.debug("Mapping IATA")       
    df_all['site']=df_all['site'].map(iata)       

    # Convert to playbook format
    logging.debug("Creating Playbook")   
    #logging.debug(display(df_all))
    df_res = df_all.groupby(['site','bgp'])['percent'].sum().unstack().T.fillna(0)

    if (routing_option):
        # Add Routing information entries to playbook
        logging.debug("Adding routing information to Playbook")
        df_routing=df_all[['bgp','routing_info']].drop_duplicates()
        df_routing=df_routing.set_index(['bgp'])
        df_res = pd.concat([df_res,df_routing], axis=1)
        df_res.index.name='bgp'
    
        #logging.debug("\n=== DF_ROUTING ===")
        #logging.debug(display(df_routing))

    df_res=df_res.reset_index()
    return df_res


#------------------------------------------------------------------------------
def playbook_to_fsdb(df, outfile):
    ''' Save playbook in FSDB format to be used by playbook_tuner
    receive: playbook dataframe
    '''

    logging.debug("playbook_to_fsdb")
    # open file to save playbook in FSDB format
    f = open(outfile, "wt")
    
    # get sites info
    sites=df.columns.to_list()
    # remove 1st column header (bgp or site)
    #sites.remove('bgp')
    del sites[0]
    
    # nrosites to fsdb header
    f.write(f'{str(len(sites))}\n')
    
    # sites to fsdb
    line=( '\t'.join(map(str,sites)))
    f.write(f'{line}\n')
    
    # limit site load to fsdb
    limits=[50000.0]*len(sites)
    line='\t'.join(map(str,limits))
    f.write(f'{line}\n')

    #logging.debug(display(df)) 

    # This is a kludge for playbook-tuner (need a Baseline with "B" uppercase)
    # Change other 'baseline' word variation to 'Baseline'
    baseline_df=df[df['bgp'].str.contains(r'(?:\s|^)baseline(?:\s|$)',case=False)]
    
    if ( baseline_df['bgp'].count()==1 ):
        df['bgp']=df['bgp'].str.replace(r'(?:\s|^)baseline(?:\s|$)','Baseline')
    elif ( baseline_df['bgp'].count()<1 ):
        print ('ERROR: No baseline - Baseline is needed for playbook-tuner')
    elif ( baseline_df['bgp'].count()>1 ):
        print('Take care. You selected more than one BASELINE')
        print('Cant generate a trustable playbook')    
        print('Tip: Chose only the right one')    
      
    # all bgp policies to fsdb
    logging.debug(f'fsdb:: {df.index}')
    for index, row in df.iterrows():
        #print (row)
        line=( '\t'.join(map(str,row.to_list())))
        logging.debug(f'FSDB:: line = {line}')
        f.write(f'{line}\n')

    f.close()    



#------------------------------------------------------------------------------
def set_log_level(log_level=logging.INFO):
    """Sets the log level of the notebook. Per default this is 'INFO' but
    can be changed.
    :param level: level to be passed to logging (defaults to 'INFO')
    :type level: str
    """
    importlib.reload(logging)
    logging.basicConfig(
            level=log_level,
            format='%(asctime)s.%(msecs)03d %(levelname)s - %(message)s',
            datefmt='%Y-%m-%d %H:%M:%S',
    )

#------------------------------------------------------------------------------
# check parameters
def evaluate_args():
    parser = parser_args()
    args, unknown = parser.parse_known_args()
    #args = parser.parse_args()

    if (unknown):
        print (f'Unknow argument {unknown}')
        parser.print_help()
        print ('')
        sys.exit(0)

    if (args.verbose):
        set_log_level('INFO')
        logging.debug(args)

    if (args.debug):
        set_log_level('DEBUG')
        logging.debug(args)

    if (args.version):
        print (version)
        sys.exit(0)

    if (args.dir):
        return (args)

   
    parser.print_help()
    print ("\nyou should enter at least one folder to analyze (--dir)")
    sys.exit(0)


###############################################################################
### Main Process

if __name__ == '__main__':
    signal.signal(signal.SIGINT, signal_handler)
    set_log_level('ERROR')
    args = evaluate_args()
 
    if (args.dir):
        df_all=pd.DataFrame()

        # check all folders pointed at command line arguments
        for stats_dir in args.dir:
            logging.info(f'Reading: [{stats_dir}]')
    
            # load all stats file on folder to df
            df=read_vpcli_stats_folder(stats_dir, args.routing)
            df_all=df_all.append(df)

        # Case you are mixing sites (policy using different sites)
        # just fill with zero sites not used on that policy
        df_all=df_all.fillna(0)
        print ('=== Playbook ===')
        display(df_all)
        print ('================')


        # Save results 
        if (args.out):
            df_all.to_csv(args.out, index=False)
            print(f'Playbook CSV saved to [{args.out}]')

        # Saving to FSDB playbook format 
        if (args.fsdb):
            playbook_to_fsdb(df_all,args.fsdb)
            print(f'Playbook FSDB saved to [{args.fsdb}]')


    





